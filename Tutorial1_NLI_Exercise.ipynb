{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLI Exercise.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajfisch/deeplearning_bootcamp_2020/blob/master/NLI_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yXAB2YFIhjZ7"
      },
      "source": [
        "# Building a Natural Language Inference Classifier\n",
        "\n",
        "Natural language inference is the task of determining whether or not a given statement (the \"hypothesis\") is entailed by another given statement (the \"premise\").\n",
        "\n",
        "The hypothesis is true (entailment) if it is entailed, it is false (contradiction) if it is not entailed, and it is undetermined (neutral) if it is neither true nor false.\n",
        "\n",
        "An example is:\n",
        "\n",
        "| Premise | Label | Hypothesis |\n",
        "| ---  | --- | --- |\n",
        "|The Golden State Warriors scored 100 points last night.| Entailment | Someone scored a basket in the game. |\n",
        "|The Golden State Warriors scored 100 points last night. | Neutral | The Warriors won the game. |\n",
        "| The Golden State Warriors scored 100 points last night. | Contradiction | The Warriors struggled to make baskets. |\n",
        "\n",
        "\n",
        "## Dataset\n",
        "\n",
        "For this exercise we'll be using a portion of the [MNLI](https://arxiv.org/abs/1704.05426) dataset --- a dataset for natural language inference that spans multiple genres and writing styles. To keep things simple, we will only be dealing with the \"Entailment\" and \"Contradiction\" classes --- making it a binary classification task.\n",
        "\n",
        "The data is provided to you as a list of entries, where each `entry` has the following structure:\n",
        "\n",
        "```\n",
        "example.x1 = [\"the\", \"tokenized\", \"premise\"]\n",
        "example.x2 = [\"the\", \"tokenized\", \"hypothesis\"]\n",
        "example.y = 0 or 1\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FYUFWtjssSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data.\n",
        "!wget https://people.csail.mit.edu/fisch/assets/data/bootcamp/nli/train.txt\n",
        "!wget https://people.csail.mit.edu/fisch/assets/data/bootcamp/nli/valid.txt\n",
        "!wget https://people.csail.mit.edu/fisch/assets/data/bootcamp/nli/test.txt\n",
        "\n",
        "import collections\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "LABELS = [\"contradiction\", \"entailment\"]\n",
        "\n",
        "Example = collections.namedtuple(\"Entry\", [\"x1\", \"x2\", \"y\"])\n",
        "\n",
        "def load_data(filename):\n",
        "  examples = []\n",
        "  with open(filename, \"r\") as f:\n",
        "    for line in f:\n",
        "      fields = json.loads(line)\n",
        "      x1 = fields[\"x1\"]\n",
        "      x2 = fields[\"x2\"]\n",
        "      if fields[\"y\"] not in LABELS:\n",
        "        continue\n",
        "      y = LABELS.index(fields[\"y\"])\n",
        "      examples.append(Example(x1, x2, y))\n",
        "  return examples\n",
        "\n",
        "train_examples = load_data(\"train.txt\")\n",
        "valid_examples = load_data(\"valid.txt\")\n",
        "test_examples = load_data(\"test.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRrG0gKopRxi",
        "colab_type": "text"
      },
      "source": [
        "## Feature Engineering\n",
        "\n",
        "As you can see from the example, this task takes **two** inputs $x_1$ and $x_2$. We'll experiment with some basic featurization options.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmFkLOM8ygfJ",
        "colab_type": "text"
      },
      "source": [
        "### Majority baseline\n",
        "\n",
        "It's always good to start simple when approaching new task. Na√Øve baselines are often good at uncovering biases in the data you might not have noticed otherwise.\n",
        "\n",
        "One to start out with is the majority baseline. What is the prior for entailment? In this model simply ignore the input and use the most common class, always.\n",
        "\n",
        "We can use the [DummyClassifier](https://scikit-learn.org/stable/modules/model_evaluation.html#dummy-estimators) from `sklearn`, create a majority baseline and record the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHMMdjJfzGNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "majority_baseline = DummyClassifier(strategy='most_frequent', random_state=0)\n",
        "\n",
        "X_train = np.ones([len(train_examples)])\n",
        "Y_train = np.array([ex.y for ex in train_examples])\n",
        "X_valid = np.ones([len(valid_examples)])\n",
        "Y_valid = np.array([ex.y for ex in valid_examples])\n",
        "\n",
        "majority_baseline.fit(X_train, Y_train)\n",
        "majority_accuracy = majority_baseline.score(X_valid, Y_valid)\n",
        "print(majority_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HNylZ4dmFfW",
        "colab_type": "text"
      },
      "source": [
        "## Exercise:\n",
        "\n",
        "1. Using Y_train, calculate the priors for the different labels. What is the most frequent class?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsgIKIkimen1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write code here!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQoLpMZ4uDcN",
        "colab_type": "text"
      },
      "source": [
        "### Hypothesis- and premise-only baselines\n",
        "\n",
        "Two other simple baselines are to try to classify the data using just the hypothesis (and no premise) and just the premise (and no hypothesis). We will use a bag-of-words representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3qofsHBuHAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Set vocab using train text.\n",
        "min_df = 5\n",
        "max_features = 1000\n",
        "vectorizer = CountVectorizer(min_df=min_df, max_features=max_features)\n",
        "vectorizer.fit([\" \".join(ex.x1) for ex in train_examples] +\n",
        "               [\" \".join(ex.x2) for ex in train_examples])\n",
        "\n",
        "train_hypothesis_only = vectorizer.transform([\" \".join(ex.x1) for ex in train_examples])\n",
        "valid_hypothesis_only = vectorizer.transform([\" \".join(ex.x1) for ex in valid_examples])\n",
        "\n",
        "train_premise_only = vectorizer.transform([\" \".join(ex.x2) for ex in train_examples])\n",
        "valid_premise_only = vectorizer.transform([\" \".join(ex.x2) for ex in valid_examples])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxpfBG9NpN8w",
        "colab_type": "text"
      },
      "source": [
        "### Independent features\n",
        "\n",
        "Let's now create a featurization that includes both $x_1$ and $x_2$. A simple one to begin with is the concatenation of their bag-of-words vectors: $[\\texttt{BoW}(x_1); \\texttt{BoW}(x_2)]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X9aaZHqvQJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "\n",
        "# Simply concatenate the two featurizations together.\n",
        "train_concatenated = scipy.sparse.hstack([train_premise_only, train_hypothesis_only])\n",
        "valid_concatenated = scipy.sparse.hstack([valid_premise_only, valid_hypothesis_only])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1EjeJGPxevR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_overlap = np.maximum(train_hypothesis_only.toarray(),\n",
        "                           train_premise_only.toarray())\n",
        "valid_overlap = np.maximum(valid_hypothesis_only.toarray(),\n",
        "                           valid_premise_only.toarray())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODRF2d_Mx8xT",
        "colab_type": "text"
      },
      "source": [
        "## Modeling\n",
        "\n",
        "Using the different featurizations as inputs, we can now experiment with different modeling choices using `sklearn`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtmO8CH56JKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "features = {\n",
        "  \"hyp_only\": (train_hypothesis_only, valid_hypothesis_only),\n",
        "  \"prem_only\": (train_premise_only, valid_premise_only),\n",
        "  \"concat\": (train_concatenated, valid_concatenated),\n",
        "}\n",
        "\n",
        "models = {\n",
        "    \"logreg\": LogisticRegression,\n",
        "    \"rand_forest\": RandomForestClassifier,\n",
        "}\n",
        "\n",
        "accuracies = collections.defaultdict(dict)\n",
        "for name, (train, valid) in features.items():\n",
        "  print(\"Running on %s\" % name)\n",
        "  for model_name, model_class in models.items():\n",
        "    print(\"Using %s\" % model_name)\n",
        "    # Put extra hyper-params here...\n",
        "    model = model_class()\n",
        "    clf = model.fit(train, Y_train)\n",
        "    accuracies[name][model_name] = clf.score(valid, Y_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FwzLHuGCIFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, model_acc in accuracies.items():\n",
        "  print(name)\n",
        "  for model, acc in model_acc.items():\n",
        "    print('\\t%s: %2.2f' % (model, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}